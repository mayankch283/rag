{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957b628b-6f5a-4410-a091-ff311856496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq sentence-transformers nltk pypdf langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535c3589-06a3-4db5-9d70-dc51cb795b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.11.8-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.13a0+0d33366-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/texttable-1.7.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/igraph-0.11.8-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: rapidocr-onnxruntime in /usr/local/lib/python3.12/dist-packages (1.4.4)\n",
      "Requirement already satisfied: pyclipper>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (1.3.0.post6)\n",
      "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (4.11.0.86)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
      "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (2.1.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (6.0.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (11.0.0)\n",
      "Requirement already satisfied: onnxruntime>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (1.22.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from rapidocr-onnxruntime) (4.67.1)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U rapidocr-onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60dca035-3795-4f60-b4e1-850f355d117b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Document' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow is BERT used for Information Retrieval?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m q_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(query, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m sim \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39meuclidean_sim(q_embeddings, embeddings)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py:653\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    652\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index : start_index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m--> 653\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py:1124\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;03m    Tokenizes the texts.\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py:488\u001b[0m, in \u001b[0;36mTransformer.tokenize\u001b[0;34m(self, texts, padding)\u001b[0m\n\u001b[1;32m    486\u001b[0m batch1, batch2 \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_tuple \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[0;32m--> 488\u001b[0m     batch1\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtext_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    489\u001b[0m     batch2\u001b[38;5;241m.\u001b[39mappend(text_tuple[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    490\u001b[0m to_tokenize \u001b[38;5;241m=\u001b[39m [batch1, batch2]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Document' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.parsers import RapidOCRBlobParser\n",
    "# from pypdf import PdfReader\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\", device='cuda')\n",
    "\n",
    "loader = PyPDFLoader('BERTforIR.pdf')\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "query = \"How is BERT used for Information Retrieval?\"\n",
    "\n",
    "q_embeddings = model.encode(query, convert_to_tensor=True)\n",
    "embeddings = model.encode(chunks, convert_to_tensor=True)\n",
    "\n",
    "sim = util.euclidean_sim(q_embeddings, embeddings)[0]\n",
    "k = 10\n",
    "top_results = torch.topk(sim, k=k)\n",
    "\n",
    "for score, idx in zip(top_results.values, top_results.indices):\n",
    "    print(f\"{chunks[idx]} (Score: {score.item():.4f})\", end = '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "815713e7-8d91-4307-96ca-82addf218f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This enables the reader to understand BERT-related models from\\nvarious perspectives in a step-by-step manner and discover new research opportunities by following this organization.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[util.semantic_search(q_embeddings, embeddings)[0][2]['corpus_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "75316f7f-4a0a-4ee0-a3ad-96798bfd3c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cos_sim in module sentence_transformers.util:\n",
      "\n",
      "cos_sim(a: 'list | np.ndarray | Tensor', b: 'list | np.ndarray | Tensor') -> 'Tensor'\n",
      "    Computes the cosine similarity between two tensors.\n",
      "\n",
      "    Args:\n",
      "        a (Union[list, np.ndarray, Tensor]): The first tensor.\n",
      "        b (Union[list, np.ndarray, Tensor]): The second tensor.\n",
      "\n",
      "    Returns:\n",
      "        Tensor: Matrix with res[i][j] = cos_sim(a[i], b[j])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(util.cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee631df-aa95-40dc-88b0-baf25ab88a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
